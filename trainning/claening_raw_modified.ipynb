{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "execution_state": "idle",
   "id": "077a78f3-5a7e-4770-80e0-3764fe9f3480",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T05:49:08.305637Z",
     "iopub.status.busy": "2025-12-10T05:49:08.305352Z",
     "iopub.status.idle": "2025-12-10T05:49:13.394235Z",
     "shell.execute_reply": "2025-12-10T05:49:13.392364Z",
     "shell.execute_reply.started": "2025-12-10T05:49:08.305615Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AnalysisException:[PATH_NOT_FOUND] Path does not exist: file:/tmp/sss.\n",
      "Unable to run statement for connection: project.spark.compatibility. Error: Code execution failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection: project.spark.compatibility | Run start time: 2025-12-10 05:49:08.853330 | Run duration : 0:00:03.641964s.\n"
     ]
    },
    {
     "ename": "ExecutionException",
     "evalue": "Code execution failed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mExecutionException\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpyspark\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mproject.spark.compatibility\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfrom pyspark.sql.functions import *\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mfrom pyspark.sql.types import StringType\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mfrom pyspark.sql.types import StringType\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mfrom pyspark.sql.functions import udf, col, length, when\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mimport re\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mdf = spark.read.option(\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mheader\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m).csv(\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py:2543\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2541\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2542\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2543\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2545\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2546\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2547\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2548\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker_studio_dataengineering_sessions/sagemaker_connection_magic/sagemaker_connection_magic.py:216\u001b[0m, in \u001b[0;36mSageMakerConnectionMagic.pyspark\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect(connection_name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m, cell)\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mExecutionException\u001b[0m: Code execution failed"
     ]
    },
    {
     "data": {
      "application/sagemaker-interactive-debugging": {
       "cell_id": "077a78f3-5a7e-4770-80e0-3764fe9f3480",
       "debugging_info_folder": "/home/sagemaker-user/shared/.temp_sagemaker_unified_studio_debugging_info/077a78f3-5a7e-4770-80e0-3764fe9f3480",
       "instruction_file": "/home/sagemaker-user/shared/.temp_sagemaker_unified_studio_debugging_info/spark_debugging_sop.txt",
       "magic_command": "%%pyspark",
       "session_type": "GlueSession"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%pyspark project.spark.compatibility\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.functions import udf, col, length, when\n",
    "import re\n",
    "\n",
    "\n",
    "df = spark.read.option(\"header\", \"true\").csv(\"raw_path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "execution_state": "idle",
   "id": "338315dc-af91-46f4-a35c-a84b6ab49928",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-12-10T05:49:13.397467Z",
     "iopub.status.idle": "2025-12-10T05:49:13.399790Z",
     "shell.execute_reply": "2025-12-10T05:49:13.398946Z",
     "shell.execute_reply.started": "2025-12-10T05:49:13.398918Z"
    }
   },
   "outputs": [],
   "source": [
    "%%pyspark project.spark.compatibility\n",
    "# Enter your code at the start of this line to replace this comment\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "execution_state": "idle",
   "id": "8f9dbb72-c52c-4e11-bec9-c4f3c0b91656",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T05:49:16.036899Z",
     "iopub.status.busy": "2025-12-10T05:49:16.036651Z",
     "iopub.status.idle": "2025-12-10T05:49:19.480354Z",
     "shell.execute_reply": "2025-12-10T05:49:19.479024Z",
     "shell.execute_reply.started": "2025-12-10T05:49:16.036878Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Connection: project.spark.compatibility | Run start time: 2025-12-10 05:49:16.039503 | Run duration : 0:00:03.437275s.\n"
     ]
    }
   ],
   "source": [
    "%%pyspark project.spark.compatibility\n",
    "# Enter your code at the start of this line to replace this comment\n",
    "\n",
    "def clean_text_combined(text):\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    \n",
    "    try:\n",
    "        # HTML 태그와 엔티티 처리\n",
    "        text = re.sub(r'<br>', ' ', text)\n",
    "        text = re.sub(r'</br>', ' ', text)\n",
    "        text = re.sub(r'<br\\s*/?>', ' ', text)\n",
    "        text = re.sub(r'<[^>]+>', '', text)\n",
    "        text = re.sub(r'<[^&]*>', '', text)\n",
    "        text = re.sub(r'&[a-zA-Z0-9#]+;', '', text)\n",
    "        \n",
    "        # URL, 전화번호, 괄호 내용 제거\n",
    "        text = re.sub(r'http[s]?://\\S+', '', text)\n",
    "        text = re.sub(r'\\d{4}-\\d{4}', '', text)\n",
    "        text = re.sub(r'\\([^)]*\\)', '', text)\n",
    "        text = re.sub(r'^\\(광고\\)', '', text)\n",
    "        \n",
    "        # 특정 키워드 포함 줄 제거\n",
    "        lines = text.split('\\n')\n",
    "        filtered_lines = []\n",
    "        for line in lines:\n",
    "            if not any(keyword in line for keyword in ['무료수신거부', '준법', '광고']):\n",
    "                filtered_lines.append(line)\n",
    "        \n",
    "        text = '\\n'.join(filtered_lines)\n",
    "        \n",
    "        # 특수문자 제거\n",
    "        special_chars = ['※', '◆', '■', '▶', '★', '☞', '☎', 'br', 'brbr']\n",
    "        for char in special_chars:\n",
    "            text = text.replace(char, '')\n",
    "        \n",
    "        # 연속된 공백과 줄바꿈 정리\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        \n",
    "        return text\n",
    "    except:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "execution_state": "idle",
   "id": "4a7b6b39-8909-4563-910d-5ce09e8c71a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T05:49:19.481411Z",
     "iopub.status.busy": "2025-12-10T05:49:19.481199Z",
     "iopub.status.idle": "2025-12-10T05:49:23.436090Z",
     "shell.execute_reply": "2025-12-10T05:49:23.434763Z",
     "shell.execute_reply.started": "2025-12-10T05:49:19.481393Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Connection: project.spark.compatibility | Run start time: 2025-12-10 05:49:19.483518 | Run duration : 0:00:03.947500s.\n"
     ]
    }
   ],
   "source": [
    "%%pyspark project.spark.compatibility\n",
    "# Enter your code at the start of this line to replace this comment\n",
    "clean_text_combined_udf = udf(clean_text_combined, StringType())\n",
    "df_final = df.withColumn(\"contents_final\", clean_text_combined_udf(col(\"contents\"))) \\\n",
    "            .filter(length(col(\"contents_final\")) > 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "execution_state": "idle",
   "id": "19726016-58b2-4ee2-88fc-8d31272bd210",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T05:49:23.437167Z",
     "iopub.status.busy": "2025-12-10T05:49:23.436930Z",
     "iopub.status.idle": "2025-12-10T05:49:26.982759Z",
     "shell.execute_reply": "2025-12-10T05:49:26.981591Z",
     "shell.execute_reply.started": "2025-12-10T05:49:23.437147Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Connection: project.spark.compatibility | Run start time: 2025-12-10 05:49:23.439173 | Run duration : 0:00:03.540724s.\n"
     ]
    }
   ],
   "source": [
    "%%pyspark project.spark.compatibility\n",
    "# Enter your code at the start of this line to replace this comment\n",
    "df_cleaned_two=df_final.select('title', 'contents_final', 'label', 'frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "execution_state": "idle",
   "id": "7bdc8c07-b023-4c91-aea3-9e9225852c0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T05:49:49.365712Z",
     "iopub.status.busy": "2025-12-10T05:49:49.365383Z",
     "iopub.status.idle": "2025-12-10T05:49:50.264389Z",
     "shell.execute_reply": "2025-12-10T05:49:50.263779Z",
     "shell.execute_reply.started": "2025-12-10T05:49:49.365688Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection: project.spark.compatibility | Run start time: 2025-12-10 05:49:49.366991 | Run duration : 0:00:00.894828s.\n"
     ]
    }
   ],
   "source": [
    "%%pyspark project.spark.compatibility\n",
    "# Enter your code at the start of this line to replace this comment\n",
    "df_cleaned_two.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "execution_state": "idle",
   "id": "d58b4941-887b-472c-af94-e1ba7f8c5cd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T05:49:34.558324Z",
     "iopub.status.busy": "2025-12-10T05:49:34.558102Z",
     "iopub.status.idle": "2025-12-10T05:49:38.115972Z",
     "shell.execute_reply": "2025-12-10T05:49:38.114817Z",
     "shell.execute_reply.started": "2025-12-10T05:49:34.558304Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Connection: project.spark.compatibility | Run start time: 2025-12-10 05:49:34.560662 | Run duration : 0:00:03.552706s.\n"
     ]
    }
   ],
   "source": [
    "%%pyspark project.spark.compatibility\n",
    "# Enter your code at the start of this line to replace this comment\n",
    "df_filtered = df_cleaned_two.filter(col(\"label\").isin([\"Y\", \"N\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "execution_state": "idle",
   "id": "1bed2bee-d67c-4fd4-a8f1-a151d40875c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T05:49:38.116584Z",
     "iopub.status.busy": "2025-12-10T05:49:38.116397Z",
     "iopub.status.idle": "2025-12-10T05:49:45.292945Z",
     "shell.execute_reply": "2025-12-10T05:49:45.291746Z",
     "shell.execute_reply.started": "2025-12-10T05:49:38.116567Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "23\n",
      "Connection: project.spark.compatibility | Run start time: 2025-12-10 05:49:38.118263 | Run duration : 0:00:07.171635s.\n"
     ]
    }
   ],
   "source": [
    "%%pyspark project.spark.compatibility\n",
    "# Enter your code at the start of this line to replace this comment\n",
    "df_filtered.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "execution_state": "idle",
   "id": "4ab72fe8-f31e-41c7-a173-2023437b8c96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T05:49:45.293800Z",
     "iopub.status.busy": "2025-12-10T05:49:45.293577Z",
     "iopub.status.idle": "2025-12-10T05:49:48.779981Z",
     "shell.execute_reply": "2025-12-10T05:49:48.778561Z",
     "shell.execute_reply.started": "2025-12-10T05:49:45.293780Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Connection: project.spark.compatibility | Run start time: 2025-12-10 05:49:45.295863 | Run duration : 0:00:03.480622s.\n"
     ]
    }
   ],
   "source": [
    "%%pyspark project.spark.compatibility\n",
    "# Enter your code at the start of this line to replace this comment\n",
    "df_filtered_final = df_filtered.filter(col(\"label\").isin([\"Y\", \"N\"])) \\\n",
    "    .withColumn(\"label\", when(col(\"label\") == \"Y\", 1).otherwise(0)) \\\n",
    "    .withColumn(\"frequency\", col(\"frequency\").cast(\"int\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "execution_state": "idle",
   "id": "857eee6e-3825-4e83-8be7-f4ef51a53c75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T05:49:59.351056Z",
     "iopub.status.busy": "2025-12-10T05:49:59.350812Z",
     "iopub.status.idle": "2025-12-10T05:50:00.368862Z",
     "shell.execute_reply": "2025-12-10T05:50:00.367571Z",
     "shell.execute_reply.started": "2025-12-10T05:49:59.351035Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection: project.spark.compatibility | Run start time: 2025-12-10 05:49:59.353000 | Run duration : 0:00:01.010064s.\n"
     ]
    }
   ],
   "source": [
    "%%pyspark project.spark.compatibility\n",
    "# Enter your code at the start of this line to replace this comment\n",
    "df_filtered_final.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "execution_state": "idle",
   "id": "79f0f8cd-f58d-44b0-b185-9faa0e3d3d0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T05:27:16.589521Z",
     "iopub.status.busy": "2025-12-10T05:27:16.589317Z",
     "iopub.status.idle": "2025-12-10T05:27:19.968054Z",
     "shell.execute_reply": "2025-12-10T05:27:19.966982Z",
     "shell.execute_reply.started": "2025-12-10T05:27:16.589502Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Connection: project.spark.compatibility | Run start time: 2025-12-10 05:27:16.591603 | Run duration : 0:00:03.373411s.\n"
     ]
    }
   ],
   "source": [
    "%%pyspark project.spark.compatibility\n",
    "# Enter your code at the start of this line to replace this comment\n",
    "# label별로 분리\n",
    "df_label_0 = df_filtered_final.filter(col(\"label\") == 0)\n",
    "df_label_1 = df_filtered_final.filter(col(\"label\") == 1)\n",
    "\n",
    "# 각각 split\n",
    "train_0, test_0 = df_label_0.randomSplit([0.7, 0.3], seed=42)\n",
    "train_1, test_1 = df_label_1.randomSplit([0.7, 0.3], seed=42)\n",
    "\n",
    "# 합치기\n",
    "train_df = train_0.union(train_1).orderBy(rand(seed=42))\n",
    "test_df = test_0.union(test_1).orderBy(rand(seed=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "execution_state": "idle",
   "id": "ce23472b-fc0a-48e4-abe3-a45a31bce712",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T05:50:05.817421Z",
     "iopub.status.busy": "2025-12-10T05:50:05.817156Z",
     "iopub.status.idle": "2025-12-10T05:50:06.748324Z",
     "shell.execute_reply": "2025-12-10T05:50:06.747003Z",
     "shell.execute_reply.started": "2025-12-10T05:50:05.817398Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection: project.spark.compatibility | Run start time: 2025-12-10 05:50:05.819591 | Run duration : 0:00:00.924274s.\n"
     ]
    }
   ],
   "source": [
    "%%pyspark project.spark.compatibility\n",
    "# Enter your code at the start of this line to replace this comment\n",
    "train_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "execution_state": "idle",
   "id": "76b6ecb0-0c5c-401a-90ab-436b2b902e70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T05:50:11.667445Z",
     "iopub.status.busy": "2025-12-10T05:50:11.667085Z",
     "iopub.status.idle": "2025-12-10T05:50:12.695608Z",
     "shell.execute_reply": "2025-12-10T05:50:12.694436Z",
     "shell.execute_reply.started": "2025-12-10T05:50:11.667308Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection: project.spark.compatibility | Run start time: 2025-12-10 05:50:11.671959 | Run duration : 0:00:01.019101s.\n"
     ]
    }
   ],
   "source": [
    "%%pyspark project.spark.compatibility\n",
    "# Enter your code at the start of this line to replace this comment\n",
    "test_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "execution_state": "idle",
   "id": "6272fc2f-94ef-4242-be91-54598a0b782a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T05:41:28.395731Z",
     "iopub.status.busy": "2025-12-10T05:41:28.395271Z",
     "iopub.status.idle": "2025-12-10T05:41:40.840240Z",
     "shell.execute_reply": "2025-12-10T05:41:40.838794Z",
     "shell.execute_reply.started": "2025-12-10T05:41:28.395699Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Connection: project.spark.compatibility | Run start time: 2025-12-10 05:41:28.892647 | Run duration : 0:00:11.944232s.\n"
     ]
    }
   ],
   "source": [
    "%%pyspark project.spark.compatibility\n",
    "# Enter your code at the start of this line to replace this comment\n",
    "train_df.write.option(\"header\",True) \\\n",
    " .csv(\"train_path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "execution_state": "idle",
   "id": "8acda0d8-c569-4b99-a563-cce4589ab657",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T05:41:40.840966Z",
     "iopub.status.busy": "2025-12-10T05:41:40.840767Z",
     "iopub.status.idle": "2025-12-10T05:41:49.724961Z",
     "shell.execute_reply": "2025-12-10T05:41:49.724046Z",
     "shell.execute_reply.started": "2025-12-10T05:41:40.840948Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Connection: project.spark.compatibility | Run start time: 2025-12-10 05:41:40.842660 | Run duration : 0:00:08.879701s.\n"
     ]
    }
   ],
   "source": [
    "%%pyspark project.spark.compatibility\n",
    "# Enter your code at the start of this line to replace this comment\n",
    "test_df.write.option(\"header\",True) \\\n",
    " .csv(\"test_path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402563fe-f928-4723-aa83-a55c117dd803",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%pyspark default.spark\n",
    "# Enter your code at the start of this line to replace this comment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
